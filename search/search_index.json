{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"What is the MNE-BIDS-Pipeline? \u00b6 The MNE-BIDS-Pipeline is a full-flegded processing pipeline for your MEG and EEG data. It operates on raw data stored according to the Brain Imaging Data Structure (BIDS). Processing is controlled using a simple human-readable configuration file. Learn more Get started","title":"Home"},{"location":"index.html#what-is-the-mne-bids-pipeline","text":"The MNE-BIDS-Pipeline is a full-flegded processing pipeline for your MEG and EEG data. It operates on raw data stored according to the Brain Imaging Data Structure (BIDS). Processing is controlled using a simple human-readable configuration file. Learn more Get started","title":"What is the MNE-BIDS-Pipeline?"},{"location":"examples/ERP_CORE.html","text":"ERP CORE. \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-015_ses-ERN_task-ERN_report.html sub-015_ses-LRP_task-LRP_report.html sub-015_ses-MMN_task-MMN_report.html sub-015_ses-N170_task-N170_report.html sub-015_ses-N2pc_task-N2pc_report.html sub-015_ses-N400_task-N400_report.html sub-015_ses-P3_task-P3_report.html sub-016_ses-ERN_task-ERN_report.html sub-016_ses-LRP_task-LRP_report.html sub-016_ses-MMN_task-MMN_report.html sub-016_ses-N170_task-N170_report.html sub-016_ses-N2pc_task-N2pc_report.html sub-016_ses-N400_task-N400_report.html sub-016_ses-P3_task-P3_report.html sub-017_ses-ERN_task-ERN_report.html sub-017_ses-LRP_task-LRP_report.html sub-017_ses-MMN_task-MMN_report.html sub-017_ses-N170_task-N170_report.html sub-017_ses-N2pc_task-N2pc_report.html sub-017_ses-N400_task-N400_report.html sub-017_ses-P3_task-P3_report.html sub-018_ses-ERN_task-ERN_report.html sub-018_ses-LRP_task-LRP_report.html sub-018_ses-MMN_task-MMN_report.html sub-018_ses-N170_task-N170_report.html sub-018_ses-N2pc_task-N2pc_report.html sub-018_ses-N400_task-N400_report.html sub-018_ses-P3_task-P3_report.html sub-019_ses-ERN_task-ERN_report.html sub-019_ses-LRP_task-LRP_report.html sub-019_ses-MMN_task-MMN_report.html sub-019_ses-N170_task-N170_report.html sub-019_ses-N2pc_task-N2pc_report.html sub-019_ses-N400_task-N400_report.html sub-019_ses-P3_task-P3_report.html sub-average_ses-ERN_task-ERN_report.html sub-average_ses-LRP_task-LRP_report.html sub-average_ses-MMN_task-MMN_report.html sub-average_ses-N170_task-N170_report.html sub-average_ses-N2pc_task-N2pc_report.html sub-average_ses-N400_task-N400_report.html sub-average_ses-P3_task-P3_report.html Data cleaning sub-015_ses-ERN_task-ERN_proc-clean_report.html sub-015_ses-ERN_task-ERN_proc-ica_report.html sub-015_ses-LRP_task-LRP_proc-clean_report.html sub-015_ses-LRP_task-LRP_proc-ica_report.html sub-015_ses-MMN_task-MMN_proc-clean_report.html sub-015_ses-MMN_task-MMN_proc-ica_report.html sub-015_ses-N170_task-N170_proc-clean_report.html sub-015_ses-N170_task-N170_proc-ica_report.html sub-015_ses-N2pc_task-N2pc_proc-clean_report.html sub-015_ses-N2pc_task-N2pc_proc-ica_report.html sub-015_ses-N400_task-N400_proc-clean_report.html sub-015_ses-N400_task-N400_proc-ica_report.html sub-015_ses-P3_task-P3_proc-clean_report.html sub-015_ses-P3_task-P3_proc-ica_report.html sub-016_ses-ERN_task-ERN_proc-clean_report.html sub-016_ses-ERN_task-ERN_proc-ica_report.html sub-016_ses-LRP_task-LRP_proc-clean_report.html sub-016_ses-LRP_task-LRP_proc-ica_report.html sub-016_ses-MMN_task-MMN_proc-clean_report.html sub-016_ses-MMN_task-MMN_proc-ica_report.html sub-016_ses-N170_task-N170_proc-clean_report.html sub-016_ses-N170_task-N170_proc-ica_report.html sub-016_ses-N2pc_task-N2pc_proc-clean_report.html sub-016_ses-N2pc_task-N2pc_proc-ica_report.html sub-016_ses-N400_task-N400_proc-clean_report.html sub-016_ses-N400_task-N400_proc-ica_report.html sub-016_ses-P3_task-P3_proc-clean_report.html sub-016_ses-P3_task-P3_proc-ica_report.html sub-017_ses-ERN_task-ERN_proc-clean_report.html sub-017_ses-ERN_task-ERN_proc-ica_report.html sub-017_ses-LRP_task-LRP_proc-clean_report.html sub-017_ses-LRP_task-LRP_proc-ica_report.html sub-017_ses-MMN_task-MMN_proc-clean_report.html sub-017_ses-MMN_task-MMN_proc-ica_report.html sub-017_ses-N170_task-N170_proc-clean_report.html sub-017_ses-N170_task-N170_proc-ica_report.html sub-017_ses-N2pc_task-N2pc_proc-clean_report.html sub-017_ses-N2pc_task-N2pc_proc-ica_report.html sub-017_ses-N400_task-N400_proc-clean_report.html sub-017_ses-N400_task-N400_proc-ica_report.html sub-017_ses-P3_task-P3_proc-clean_report.html sub-017_ses-P3_task-P3_proc-ica_report.html sub-018_ses-ERN_task-ERN_proc-clean_report.html sub-018_ses-ERN_task-ERN_proc-ica_report.html sub-018_ses-LRP_task-LRP_proc-clean_report.html sub-018_ses-LRP_task-LRP_proc-ica_report.html sub-018_ses-MMN_task-MMN_proc-clean_report.html sub-018_ses-MMN_task-MMN_proc-ica_report.html sub-018_ses-N170_task-N170_proc-clean_report.html sub-018_ses-N170_task-N170_proc-ica_report.html sub-018_ses-N2pc_task-N2pc_proc-clean_report.html sub-018_ses-N2pc_task-N2pc_proc-ica_report.html sub-018_ses-N400_task-N400_proc-clean_report.html sub-018_ses-N400_task-N400_proc-ica_report.html sub-018_ses-P3_task-P3_proc-clean_report.html sub-018_ses-P3_task-P3_proc-ica_report.html sub-019_ses-ERN_task-ERN_proc-clean_report.html sub-019_ses-ERN_task-ERN_proc-ica_report.html sub-019_ses-LRP_task-LRP_proc-clean_report.html sub-019_ses-LRP_task-LRP_proc-ica_report.html sub-019_ses-MMN_task-MMN_proc-clean_report.html sub-019_ses-MMN_task-MMN_proc-ica_report.html sub-019_ses-N170_task-N170_proc-clean_report.html sub-019_ses-N170_task-N170_proc-ica_report.html sub-019_ses-N2pc_task-N2pc_proc-clean_report.html sub-019_ses-N2pc_task-N2pc_proc-ica_report.html sub-019_ses-N400_task-N400_proc-clean_report.html sub-019_ses-N400_task-N400_proc-ica_report.html sub-019_ses-P3_task-P3_proc-clean_report.html sub-019_ses-P3_task-P3_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://osf.io/3zk6n/download Configuration \u00b6 import os study_name = 'ERP-CORE' bids_root = '~/mne_data/ERP_CORE' task = os . environ . get ( 'MNE_BIDS_STUDY_TASK' ) sessions = [ task ] subjects = [ '015' , '016' , '017' , '018' , '019' ] ch_types = [ 'eeg' ] interactive = False resample_sfreq = 256 eeg_template_montage = 'standard_1005' eeg_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'FP2' )} drop_channels = [ 'HEOG_left' , 'HEOG_right' , 'VEOG_lower' ] l_freq = 0.1 h_freq = None decode = True use_ssp = False use_ica = True ica_max_iterations = 1000 ica_eog_threshold = 2 run_source_estimation = False on_error = 'abort' on_rename_missing_events = 'warn' N_JOBS = 10 if task == 'N400' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/prime/related' , 'stimulus/112' : 'stimulus/prime/related' , 'stimulus/121' : 'stimulus/prime/unrelated' , 'stimulus/122' : 'stimulus/prime/unrelated' , 'stimulus/211' : 'stimulus/target/related' , 'stimulus/212' : 'stimulus/target/related' , 'stimulus/221' : 'stimulus/target/unrelated' , 'stimulus/222' : 'stimulus/target/unrelated' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tim = - 0.2 epochs_tmax = 0.8 epochs_metadata_tmin = 0 epochs_metadata_tmax = 1.5 epochs_metadata_keep_first = [ 'stimulus/target' , 'response' ] baseline = ( None , 0 ) conditions = { 'related' : '`first_stimulus/target` == \"related\" and ' 'first_response == \"correct\"' , 'unrelated' : '`first_stimulus/target` == \"unrelated\" and ' 'first_response == \"correct\"' } contrasts = [( 'unrelated' , 'related' )] elif task == 'ERN' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/correct' , 'response/112' : 'response/incorrect' , 'response/121' : 'response/correct' , 'response/122' : 'response/incorrect' , 'response/211' : 'response/incorrect' , 'response/212' : 'response/correct' , 'response/221' : 'response/incorrect' , 'response/222' : 'response/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.6 epochs_tmax = 0.4 baseline = ( - 0.4 , - 0.2 ) conditions = [ 'response/correct' , 'response/incorrect' ] contrasts = [( 'response/incorrect' , 'response/correct' )] elif task == 'LRP' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/left/correct' , 'response/112' : 'response/left/incorrect' , 'response/121' : 'response/left/correct' , 'response/122' : 'response/left/incorrect' , 'response/211' : 'response/right/incorrect' , 'response/212' : 'response/right/correct' , 'response/221' : 'response/right/incorrect' , 'response/222' : 'response/right/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.8 epochs_tmax = 0.2 baseline = ( None , - 0.6 ) conditions = [ 'response/left' , 'response/right' ] contrasts = [( 'response/right' , 'response/left' )] # contralateral vs ipsi elif task == 'MMN' : rename_events = { 'stimulus/70' : 'stimulus/deviant' , 'stimulus/80' : 'stimulus/standard' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/standard' , 'stimulus/deviant' ] contrasts = [( 'stimulus/deviant' , 'stimulus/standard' )] elif task == 'N2pc' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/blue/left' , 'stimulus/112' : 'stimulus/blue/left' , 'stimulus/121' : 'stimulus/blue/right' , 'stimulus/122' : 'stimulus/blue/right' , 'stimulus/211' : 'stimulus/pink/left' , 'stimulus/212' : 'stimulus/pink/left' , 'stimulus/221' : 'stimulus/pink/right' , 'stimulus/222' : 'stimulus/pink/right' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/right' , 'stimulus/left' ] contrasts = [( 'stimulus/right' , 'stimulus/left' )] # Contralteral vs ipsi elif task == 'N170' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' } eeg_reference = 'average' ica_n_components = 30 - 1 for i in range ( 1 , 180 + 1 ): orig_name = f 'stimulus/ { i } ' if 1 <= i <= 40 : new_name = f 'stimulus/face/normal' elif 41 <= i <= 80 : new_name = f 'stimulus/car/normal' elif 101 <= i <= 140 : new_name = f 'stimulus/face/scrambled' elif 141 <= i <= 180 : new_name = f 'stimulus/car/scrambled' else : continue rename_events [ orig_name ] = new_name tmin = - 0.2 tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/face/normal' , 'stimulus/car/normal' ] contrasts = [( 'stimulus/face/normal' , 'stimulus/car/normal' )] elif task == 'P3' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/incorrect' , 'stimulus/11' : 'stimulus/target/11' , 'stimulus/22' : 'stimulus/target/22' , 'stimulus/33' : 'stimulus/target/33' , 'stimulus/44' : 'stimulus/target/44' , 'stimulus/55' : 'stimulus/target/55' , 'stimulus/21' : 'stimulus/non-target/21' , 'stimulus/31' : 'stimulus/non-target/31' , 'stimulus/41' : 'stimulus/non-target/41' , 'stimulus/51' : 'stimulus/non-target/51' , 'stimulus/12' : 'stimulus/non-target/12' , 'stimulus/32' : 'stimulus/non-target/32' , 'stimulus/42' : 'stimulus/non-target/42' , 'stimulus/52' : 'stimulus/non-target/52' , 'stimulus/13' : 'stimulus/non-target/13' , 'stimulus/23' : 'stimulus/non-target/23' , 'stimulus/43' : 'stimulus/non-target/43' , 'stimulus/53' : 'stimulus/non-target/53' , 'stimulus/14' : 'stimulus/non-target/14' , 'stimulus/24' : 'stimulus/non-target/24' , 'stimulus/34' : 'stimulus/non-target/34' , 'stimulus/54' : 'stimulus/non-target/54' , 'stimulus/15' : 'stimulus/non-target/15' , 'stimulus/25' : 'stimulus/non-target/25' , 'stimulus/35' : 'stimulus/non-target/35' , 'stimulus/45' : 'stimulus/non-target/45' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/target' , 'stimulus/non-target' ] contrasts = [( 'stimulus/target' , 'stimulus/non-target' )] else : raise RuntimeError ( f 'Task { task } not currently supported' )","title":"ERP CORE."},{"location":"examples/ERP_CORE.html#erp-core","text":"","title":"ERP CORE."},{"location":"examples/ERP_CORE.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ERP_CORE.html#generated-output","text":"Summary reports sub-015_ses-ERN_task-ERN_report.html sub-015_ses-LRP_task-LRP_report.html sub-015_ses-MMN_task-MMN_report.html sub-015_ses-N170_task-N170_report.html sub-015_ses-N2pc_task-N2pc_report.html sub-015_ses-N400_task-N400_report.html sub-015_ses-P3_task-P3_report.html sub-016_ses-ERN_task-ERN_report.html sub-016_ses-LRP_task-LRP_report.html sub-016_ses-MMN_task-MMN_report.html sub-016_ses-N170_task-N170_report.html sub-016_ses-N2pc_task-N2pc_report.html sub-016_ses-N400_task-N400_report.html sub-016_ses-P3_task-P3_report.html sub-017_ses-ERN_task-ERN_report.html sub-017_ses-LRP_task-LRP_report.html sub-017_ses-MMN_task-MMN_report.html sub-017_ses-N170_task-N170_report.html sub-017_ses-N2pc_task-N2pc_report.html sub-017_ses-N400_task-N400_report.html sub-017_ses-P3_task-P3_report.html sub-018_ses-ERN_task-ERN_report.html sub-018_ses-LRP_task-LRP_report.html sub-018_ses-MMN_task-MMN_report.html sub-018_ses-N170_task-N170_report.html sub-018_ses-N2pc_task-N2pc_report.html sub-018_ses-N400_task-N400_report.html sub-018_ses-P3_task-P3_report.html sub-019_ses-ERN_task-ERN_report.html sub-019_ses-LRP_task-LRP_report.html sub-019_ses-MMN_task-MMN_report.html sub-019_ses-N170_task-N170_report.html sub-019_ses-N2pc_task-N2pc_report.html sub-019_ses-N400_task-N400_report.html sub-019_ses-P3_task-P3_report.html sub-average_ses-ERN_task-ERN_report.html sub-average_ses-LRP_task-LRP_report.html sub-average_ses-MMN_task-MMN_report.html sub-average_ses-N170_task-N170_report.html sub-average_ses-N2pc_task-N2pc_report.html sub-average_ses-N400_task-N400_report.html sub-average_ses-P3_task-P3_report.html Data cleaning sub-015_ses-ERN_task-ERN_proc-clean_report.html sub-015_ses-ERN_task-ERN_proc-ica_report.html sub-015_ses-LRP_task-LRP_proc-clean_report.html sub-015_ses-LRP_task-LRP_proc-ica_report.html sub-015_ses-MMN_task-MMN_proc-clean_report.html sub-015_ses-MMN_task-MMN_proc-ica_report.html sub-015_ses-N170_task-N170_proc-clean_report.html sub-015_ses-N170_task-N170_proc-ica_report.html sub-015_ses-N2pc_task-N2pc_proc-clean_report.html sub-015_ses-N2pc_task-N2pc_proc-ica_report.html sub-015_ses-N400_task-N400_proc-clean_report.html sub-015_ses-N400_task-N400_proc-ica_report.html sub-015_ses-P3_task-P3_proc-clean_report.html sub-015_ses-P3_task-P3_proc-ica_report.html sub-016_ses-ERN_task-ERN_proc-clean_report.html sub-016_ses-ERN_task-ERN_proc-ica_report.html sub-016_ses-LRP_task-LRP_proc-clean_report.html sub-016_ses-LRP_task-LRP_proc-ica_report.html sub-016_ses-MMN_task-MMN_proc-clean_report.html sub-016_ses-MMN_task-MMN_proc-ica_report.html sub-016_ses-N170_task-N170_proc-clean_report.html sub-016_ses-N170_task-N170_proc-ica_report.html sub-016_ses-N2pc_task-N2pc_proc-clean_report.html sub-016_ses-N2pc_task-N2pc_proc-ica_report.html sub-016_ses-N400_task-N400_proc-clean_report.html sub-016_ses-N400_task-N400_proc-ica_report.html sub-016_ses-P3_task-P3_proc-clean_report.html sub-016_ses-P3_task-P3_proc-ica_report.html sub-017_ses-ERN_task-ERN_proc-clean_report.html sub-017_ses-ERN_task-ERN_proc-ica_report.html sub-017_ses-LRP_task-LRP_proc-clean_report.html sub-017_ses-LRP_task-LRP_proc-ica_report.html sub-017_ses-MMN_task-MMN_proc-clean_report.html sub-017_ses-MMN_task-MMN_proc-ica_report.html sub-017_ses-N170_task-N170_proc-clean_report.html sub-017_ses-N170_task-N170_proc-ica_report.html sub-017_ses-N2pc_task-N2pc_proc-clean_report.html sub-017_ses-N2pc_task-N2pc_proc-ica_report.html sub-017_ses-N400_task-N400_proc-clean_report.html sub-017_ses-N400_task-N400_proc-ica_report.html sub-017_ses-P3_task-P3_proc-clean_report.html sub-017_ses-P3_task-P3_proc-ica_report.html sub-018_ses-ERN_task-ERN_proc-clean_report.html sub-018_ses-ERN_task-ERN_proc-ica_report.html sub-018_ses-LRP_task-LRP_proc-clean_report.html sub-018_ses-LRP_task-LRP_proc-ica_report.html sub-018_ses-MMN_task-MMN_proc-clean_report.html sub-018_ses-MMN_task-MMN_proc-ica_report.html sub-018_ses-N170_task-N170_proc-clean_report.html sub-018_ses-N170_task-N170_proc-ica_report.html sub-018_ses-N2pc_task-N2pc_proc-clean_report.html sub-018_ses-N2pc_task-N2pc_proc-ica_report.html sub-018_ses-N400_task-N400_proc-clean_report.html sub-018_ses-N400_task-N400_proc-ica_report.html sub-018_ses-P3_task-P3_proc-clean_report.html sub-018_ses-P3_task-P3_proc-ica_report.html sub-019_ses-ERN_task-ERN_proc-clean_report.html sub-019_ses-ERN_task-ERN_proc-ica_report.html sub-019_ses-LRP_task-LRP_proc-clean_report.html sub-019_ses-LRP_task-LRP_proc-ica_report.html sub-019_ses-MMN_task-MMN_proc-clean_report.html sub-019_ses-MMN_task-MMN_proc-ica_report.html sub-019_ses-N170_task-N170_proc-clean_report.html sub-019_ses-N170_task-N170_proc-ica_report.html sub-019_ses-N2pc_task-N2pc_proc-clean_report.html sub-019_ses-N2pc_task-N2pc_proc-ica_report.html sub-019_ses-N400_task-N400_proc-clean_report.html sub-019_ses-N400_task-N400_proc-ica_report.html sub-019_ses-P3_task-P3_proc-clean_report.html sub-019_ses-P3_task-P3_proc-ica_report.html","title":"Generated output"},{"location":"examples/ERP_CORE.html#dataset-source","text":"This dataset was acquired from https://osf.io/3zk6n/download","title":"Dataset source"},{"location":"examples/ERP_CORE.html#configuration","text":"import os study_name = 'ERP-CORE' bids_root = '~/mne_data/ERP_CORE' task = os . environ . get ( 'MNE_BIDS_STUDY_TASK' ) sessions = [ task ] subjects = [ '015' , '016' , '017' , '018' , '019' ] ch_types = [ 'eeg' ] interactive = False resample_sfreq = 256 eeg_template_montage = 'standard_1005' eeg_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'FP2' )} drop_channels = [ 'HEOG_left' , 'HEOG_right' , 'VEOG_lower' ] l_freq = 0.1 h_freq = None decode = True use_ssp = False use_ica = True ica_max_iterations = 1000 ica_eog_threshold = 2 run_source_estimation = False on_error = 'abort' on_rename_missing_events = 'warn' N_JOBS = 10 if task == 'N400' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/prime/related' , 'stimulus/112' : 'stimulus/prime/related' , 'stimulus/121' : 'stimulus/prime/unrelated' , 'stimulus/122' : 'stimulus/prime/unrelated' , 'stimulus/211' : 'stimulus/target/related' , 'stimulus/212' : 'stimulus/target/related' , 'stimulus/221' : 'stimulus/target/unrelated' , 'stimulus/222' : 'stimulus/target/unrelated' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tim = - 0.2 epochs_tmax = 0.8 epochs_metadata_tmin = 0 epochs_metadata_tmax = 1.5 epochs_metadata_keep_first = [ 'stimulus/target' , 'response' ] baseline = ( None , 0 ) conditions = { 'related' : '`first_stimulus/target` == \"related\" and ' 'first_response == \"correct\"' , 'unrelated' : '`first_stimulus/target` == \"unrelated\" and ' 'first_response == \"correct\"' } contrasts = [( 'unrelated' , 'related' )] elif task == 'ERN' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/correct' , 'response/112' : 'response/incorrect' , 'response/121' : 'response/correct' , 'response/122' : 'response/incorrect' , 'response/211' : 'response/incorrect' , 'response/212' : 'response/correct' , 'response/221' : 'response/incorrect' , 'response/222' : 'response/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.6 epochs_tmax = 0.4 baseline = ( - 0.4 , - 0.2 ) conditions = [ 'response/correct' , 'response/incorrect' ] contrasts = [( 'response/incorrect' , 'response/correct' )] elif task == 'LRP' : rename_events = { 'stimulus/11' : 'compatible/left' , 'stimulus/12' : 'compatible/right' , 'stimulus/21' : 'incompatible/left' , 'stimulus/22' : 'incompatible/right' , 'response/111' : 'response/left/correct' , 'response/112' : 'response/left/incorrect' , 'response/121' : 'response/left/correct' , 'response/122' : 'response/left/incorrect' , 'response/211' : 'response/right/incorrect' , 'response/212' : 'response/right/correct' , 'response/221' : 'response/right/incorrect' , 'response/222' : 'response/right/correct' , } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.8 epochs_tmax = 0.2 baseline = ( None , - 0.6 ) conditions = [ 'response/left' , 'response/right' ] contrasts = [( 'response/right' , 'response/left' )] # contralateral vs ipsi elif task == 'MMN' : rename_events = { 'stimulus/70' : 'stimulus/deviant' , 'stimulus/80' : 'stimulus/standard' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/standard' , 'stimulus/deviant' ] contrasts = [( 'stimulus/deviant' , 'stimulus/standard' )] elif task == 'N2pc' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' , 'stimulus/111' : 'stimulus/blue/left' , 'stimulus/112' : 'stimulus/blue/left' , 'stimulus/121' : 'stimulus/blue/right' , 'stimulus/122' : 'stimulus/blue/right' , 'stimulus/211' : 'stimulus/pink/left' , 'stimulus/212' : 'stimulus/pink/left' , 'stimulus/221' : 'stimulus/pink/right' , 'stimulus/222' : 'stimulus/pink/right' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/right' , 'stimulus/left' ] contrasts = [( 'stimulus/right' , 'stimulus/left' )] # Contralteral vs ipsi elif task == 'N170' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/error' } eeg_reference = 'average' ica_n_components = 30 - 1 for i in range ( 1 , 180 + 1 ): orig_name = f 'stimulus/ { i } ' if 1 <= i <= 40 : new_name = f 'stimulus/face/normal' elif 41 <= i <= 80 : new_name = f 'stimulus/car/normal' elif 101 <= i <= 140 : new_name = f 'stimulus/face/scrambled' elif 141 <= i <= 180 : new_name = f 'stimulus/car/scrambled' else : continue rename_events [ orig_name ] = new_name tmin = - 0.2 tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/face/normal' , 'stimulus/car/normal' ] contrasts = [( 'stimulus/face/normal' , 'stimulus/car/normal' )] elif task == 'P3' : rename_events = { 'response/201' : 'response/correct' , 'response/202' : 'response/incorrect' , 'stimulus/11' : 'stimulus/target/11' , 'stimulus/22' : 'stimulus/target/22' , 'stimulus/33' : 'stimulus/target/33' , 'stimulus/44' : 'stimulus/target/44' , 'stimulus/55' : 'stimulus/target/55' , 'stimulus/21' : 'stimulus/non-target/21' , 'stimulus/31' : 'stimulus/non-target/31' , 'stimulus/41' : 'stimulus/non-target/41' , 'stimulus/51' : 'stimulus/non-target/51' , 'stimulus/12' : 'stimulus/non-target/12' , 'stimulus/32' : 'stimulus/non-target/32' , 'stimulus/42' : 'stimulus/non-target/42' , 'stimulus/52' : 'stimulus/non-target/52' , 'stimulus/13' : 'stimulus/non-target/13' , 'stimulus/23' : 'stimulus/non-target/23' , 'stimulus/43' : 'stimulus/non-target/43' , 'stimulus/53' : 'stimulus/non-target/53' , 'stimulus/14' : 'stimulus/non-target/14' , 'stimulus/24' : 'stimulus/non-target/24' , 'stimulus/34' : 'stimulus/non-target/34' , 'stimulus/54' : 'stimulus/non-target/54' , 'stimulus/15' : 'stimulus/non-target/15' , 'stimulus/25' : 'stimulus/non-target/25' , 'stimulus/35' : 'stimulus/non-target/35' , 'stimulus/45' : 'stimulus/non-target/45' } eeg_reference = [ 'P9' , 'P10' ] ica_n_components = 30 - len ( eeg_reference ) epochs_tmin = - 0.2 epochs_tmax = 0.8 baseline = ( None , 0 ) conditions = [ 'stimulus/target' , 'stimulus/non-target' ] contrasts = [( 'stimulus/target' , 'stimulus/non-target' )] else : raise RuntimeError ( f 'Task { task } not currently supported' )","title":"Configuration"},{"location":"examples/ds000117.html","text":"Faces dataset \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_ses-meg_task-facerecognition_report.html sub-average_ses-meg_task-facerecognition_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000117 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000117 \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_coordsystem.json \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_headshape.pos Configuration \u00b6 study_name = 'ds000117' bids_root = '~/mne_data/ds000117' task = 'facerecognition' ch_types = [ 'meg' ] runs = [ '01' ] sessions = [ 'meg' ] interactive = False acq = None subjects = [ '01' ] # use_maxwell_filter = True # subjects_dir = op.join(bids_root, 'derivatives', 'freesurfer', 'subjects') reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 } conditions = [ 'Famous' , 'Unfamiliar' , 'Scrambled' ] contrasts = [( 'Famous' , 'Scrambled' ), ( 'Unfamiliar' , 'Scrambled' ), ( 'Famous' , 'Unfamiliar' )] decode = True use_ssp = False use_ica = False","title":"Faces dataset"},{"location":"examples/ds000117.html#faces-dataset","text":"","title":"Faces dataset"},{"location":"examples/ds000117.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000117.html#generated-output","text":"Summary reports sub-01_ses-meg_task-facerecognition_report.html sub-average_ses-meg_task-facerecognition_report.html","title":"Generated output"},{"location":"examples/ds000117.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000117 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000117 \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_coordsystem.json \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_events.tsv \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_task-facerecognition_run-01_meg.fif \\ --include = sub-01/ses-meg/meg/sub-01_ses-meg_headshape.pos","title":"Dataset source"},{"location":"examples/ds000117.html#configuration","text":"study_name = 'ds000117' bids_root = '~/mne_data/ds000117' task = 'facerecognition' ch_types = [ 'meg' ] runs = [ '01' ] sessions = [ 'meg' ] interactive = False acq = None subjects = [ '01' ] # use_maxwell_filter = True # subjects_dir = op.join(bids_root, 'derivatives', 'freesurfer', 'subjects') reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 } conditions = [ 'Famous' , 'Unfamiliar' , 'Scrambled' ] contrasts = [( 'Famous' , 'Scrambled' ), ( 'Unfamiliar' , 'Scrambled' ), ( 'Famous' , 'Unfamiliar' )] decode = True use_ssp = False use_ica = False","title":"Configuration"},{"location":"examples/ds000246.html","text":"Auditory MEG \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-0001_task-AEF_report.html sub-average_task-AEF_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000246 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000246 \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.json \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_channels.tsv Configuration \u00b6 study_name = 'ds000246' bids_root = '~/mne_data/ds000246' deriv_root = '~/mne_data/ds000246/derivatives/mne-bids-pipeline' runs = [ '01' ] l_freq = . 3 h_freq = 100. decim = 4 subjects = [ '0001' ] ch_types = [ 'meg' ] reject = dict ( mag = 4e-12 , eog = 250e-6 ) conditions = [ 'standard' , 'deviant' , 'button' ] contrasts = [( 'deviant' , 'standard' )] decode = True on_error = 'debug'","title":"Auditory MEG"},{"location":"examples/ds000246.html#auditory-meg","text":"","title":"Auditory MEG"},{"location":"examples/ds000246.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000246.html#generated-output","text":"Summary reports sub-0001_task-AEF_report.html sub-average_task-AEF_report.html","title":"Generated output"},{"location":"examples/ds000246.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000246 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000246 \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.ds \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_meg.json \\ --include = sub-0001/meg/sub-0001_task-AEF_run-01_channels.tsv","title":"Dataset source"},{"location":"examples/ds000246.html#configuration","text":"study_name = 'ds000246' bids_root = '~/mne_data/ds000246' deriv_root = '~/mne_data/ds000246/derivatives/mne-bids-pipeline' runs = [ '01' ] l_freq = . 3 h_freq = 100. decim = 4 subjects = [ '0001' ] ch_types = [ 'meg' ] reject = dict ( mag = 4e-12 , eog = 250e-6 ) conditions = [ 'standard' , 'deviant' , 'button' ] contrasts = [( 'deviant' , 'standard' )] decode = True on_error = 'debug'","title":"Configuration"},{"location":"examples/ds000248.html","text":"MNE Sample Data \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u2705 Generated output \u00b6 Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 \\ --include = sub-emptyroom \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage. Configuration \u00b6 study_name = 'ds000248' bids_root = '~/mne_data/ds000248' subjects = [ '01' ] rename_events = { 'Smiley' : 'Emoji' , 'Button' : 'Switch' } conditions = [ 'Auditory' , 'Visual' , 'Auditory/Left' , 'Auditory/Right' ] contrasts = [( 'Visual' , 'Auditory' ), ( 'Auditory/Right' , 'Auditory/Left' )] ch_types = [ 'meg' ] mf_reference_run = '01' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True process_er = True noise_cov = 'emptyroom' bem_mri_images = 'FLASH' recreate_bem = True","title":"MNE Sample Data"},{"location":"examples/ds000248.html#mne-sample-data","text":"","title":"MNE Sample Data"},{"location":"examples/ds000248.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u2705","title":"Demonstrated features"},{"location":"examples/ds000248.html#generated-output","text":"Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html","title":"Generated output"},{"location":"examples/ds000248.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 \\ --include = sub-emptyroom \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2005s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/mri/aparc.a2009s+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/fsaverage/xhemi/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/sub-01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.","title":"Dataset source"},{"location":"examples/ds000248.html#configuration","text":"study_name = 'ds000248' bids_root = '~/mne_data/ds000248' subjects = [ '01' ] rename_events = { 'Smiley' : 'Emoji' , 'Button' : 'Switch' } conditions = [ 'Auditory' , 'Visual' , 'Auditory/Left' , 'Auditory/Right' ] contrasts = [( 'Visual' , 'Auditory' ), ( 'Auditory/Right' , 'Auditory/Left' )] ch_types = [ 'meg' ] mf_reference_run = '01' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True process_er = True noise_cov = 'emptyroom' bem_mri_images = 'FLASH' recreate_bem = True","title":"Configuration"},{"location":"examples/ds000248_ica.html","text":"MNE Sample Data: ICA \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Data cleaning sub-01_task-audiovisual_proc-clean_report.html sub-01_task-audiovisual_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01 Configuration \u00b6 study_name = 'MNE \"sample\" dataset' bids_root = '~/mne_data/ds000248_ica' ch_types = [ 'meg' ] data_type = 'meg' subjects = [ '01' ] task = 'audiovisual' run = '01' l_freq = 0.3 h_freq = 40.0 conditions = [ 'Auditory/Left' , 'Auditory/Right' , 'Visual/Left' , 'Visual/Right' ] tmin = - 0.2 tmax = 0.5 baseline = ( None , 0 ) reject = dict ( mag = 3000e-15 , grad = 3000e-13 ) use_ssp = False use_ica = True ica_l_freq = 1.0 ica_n_components = 0.8 ica_max_iterations = 500 interactive = False","title":"MNE Sample Data: ICA"},{"location":"examples/ds000248_ica.html#mne-sample-data-ica","text":"","title":"MNE Sample Data: ICA"},{"location":"examples/ds000248_ica.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds000248_ica.html#generated-output","text":"Summary reports sub-01_task-audiovisual_report.html sub-average_task-audiovisual_report.html Data cleaning sub-01_task-audiovisual_proc-clean_report.html sub-01_task-audiovisual_proc-ica_report.html","title":"Generated output"},{"location":"examples/ds000248_ica.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds000248 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds000248 \\ --include = sub-01","title":"Dataset source"},{"location":"examples/ds000248_ica.html#configuration","text":"study_name = 'MNE \"sample\" dataset' bids_root = '~/mne_data/ds000248_ica' ch_types = [ 'meg' ] data_type = 'meg' subjects = [ '01' ] task = 'audiovisual' run = '01' l_freq = 0.3 h_freq = 40.0 conditions = [ 'Auditory/Left' , 'Auditory/Right' , 'Visual/Left' , 'Visual/Right' ] tmin = - 0.2 tmax = 0.5 baseline = ( None , 0 ) reject = dict ( mag = 3000e-15 , grad = 3000e-13 ) use_ssp = False use_ica = True ica_l_freq = 1.0 ica_n_components = 0.8 ica_max_iterations = 500 interactive = False","title":"Configuration"},{"location":"examples/ds001810.html","text":"tDCS EEG \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_ses-anodalpre_task-attentionalblink_report.html sub-02_ses-anodalpre_task-attentionalblink_report.html sub-03_ses-anodalpre_task-attentionalblink_report.html sub-04_ses-anodalpre_task-attentionalblink_report.html sub-05_ses-anodalpre_task-attentionalblink_report.html sub-average_ses-anodalpre_task-attentionalblink_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds001810 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds001810 \\ --include = sub-01/ses-anodalpre \\ --include = sub-02/ses-anodalpre \\ --include = sub-03/ses-anodalpre \\ --include = sub-04/ses-anodalpre \\ --include = sub-05/ses-anodalpre Configuration \u00b6 study_name = 'ds001810' bids_root = '~/mne_data/ds001810' task = 'attentionalblink' interactive = False ch_types = [ 'eeg' ] eeg_template_montage = 'biosemi64' reject = dict ( eeg = 100e-6 ) baseline = ( None , 0 ) conditions = [ '61450' , '61511' ] contrasts = [( '61450' , '61511' )] decode = True l_freq = 0.3 use_ssp = False subjects = [ '01' , '02' , '03' , '04' , '05' ] sessions = [ 'anodalpre' ] interpolate_bads_grand_average = False","title":"tDCS EEG"},{"location":"examples/ds001810.html#tdcs-eeg","text":"","title":"tDCS EEG"},{"location":"examples/ds001810.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds001810.html#generated-output","text":"Summary reports sub-01_ses-anodalpre_task-attentionalblink_report.html sub-02_ses-anodalpre_task-attentionalblink_report.html sub-03_ses-anodalpre_task-attentionalblink_report.html sub-04_ses-anodalpre_task-attentionalblink_report.html sub-05_ses-anodalpre_task-attentionalblink_report.html sub-average_ses-anodalpre_task-attentionalblink_report.html","title":"Generated output"},{"location":"examples/ds001810.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds001810 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds001810 \\ --include = sub-01/ses-anodalpre \\ --include = sub-02/ses-anodalpre \\ --include = sub-03/ses-anodalpre \\ --include = sub-04/ses-anodalpre \\ --include = sub-05/ses-anodalpre","title":"Dataset source"},{"location":"examples/ds001810.html#configuration","text":"study_name = 'ds001810' bids_root = '~/mne_data/ds001810' task = 'attentionalblink' interactive = False ch_types = [ 'eeg' ] eeg_template_montage = 'biosemi64' reject = dict ( eeg = 100e-6 ) baseline = ( None , 0 ) conditions = [ '61450' , '61511' ] contrasts = [( '61450' , '61511' )] decode = True l_freq = 0.3 use_ssp = False subjects = [ '01' , '02' , '03' , '04' , '05' ] sessions = [ 'anodalpre' ] interpolate_bads_grand_average = False","title":"Configuration"},{"location":"examples/ds003104.html","text":"Somato \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-somato_report.html sub-average_task-somato_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds003104 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003104 \\ --include = sub-01 \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage. Configuration \u00b6 study_name = 'MNE-somato-data-anonymized' bids_root = '~/mne_data/ds003104' conditions = [ 'somato_event1' ] ch_types = [ 'meg' ]","title":"Somato"},{"location":"examples/ds003104.html#somato","text":"","title":"Somato"},{"location":"examples/ds003104.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u274c Frequency filter \u2705 SSP \u2705 ICA \u274c Evoked contrasts \u274c Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds003104.html#generated-output","text":"Summary reports sub-01_task-somato_report.html sub-average_task-somato_report.html","title":"Generated output"},{"location":"examples/ds003104.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds003104 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003104 \\ --include = sub-01 \\ --include = derivatives/freesurfer/subjects \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.DKTatlas+aseg.mgz \\ --exclude = derivatives/freesurfer/subjects/01/mri/aparc.a2009s+aseg.mgz Note that we have to explicitly exclude files due to a problem with OpenNeuro's storage.","title":"Dataset source"},{"location":"examples/ds003104.html#configuration","text":"study_name = 'MNE-somato-data-anonymized' bids_root = '~/mne_data/ds003104' conditions = [ 'somato_event1' ] ch_types = [ 'meg' ]","title":"Configuration"},{"location":"examples/ds003392.html","text":"Localizer \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-01_task-localizer_report.html sub-average_task-localizer_report.html Data cleaning sub-01_task-localizer_proc-clean_report.html sub-01_task-localizer_proc-ica_report.html Dataset source \u00b6 This dataset was acquired from https://openneuro.org/datasets/ds003392 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003392 \\ --include = sub-01 \\ --include = sub-emptyroom/ses-19111211 Configuration \u00b6 study_name = 'localizer' bids_root = '~/mne_data/ds003392' subjects_list = [ '01' ] task = 'localizer' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True allow_maxshield = True ch_types = [ 'meg' ] l_freq = 1. h_freq = 40. resample_sfreq = 250 # Artifact correction. use_ssp = False use_ica = True ica_max_iterations = 500 ica_l_freq = 1. ica_n_components = 0.99 ica_reject_components = 'auto' # Epochs tmin = - 0.2 tmax = 1.0 baseline = ( None , 0 ) # Conditions / events to consider when epoching conditions = [ 'coherent' , 'incoherent' ] # Decoding decode = True contrasts = [( 'incoherent' , 'coherent' )] # Noise estimation process_er = True noise_cov = 'emptyroom'","title":"Localizer"},{"location":"examples/ds003392.html#localizer","text":"","title":"Localizer"},{"location":"examples/ds003392.html#demonstrated-features","text":"Feature This example MEG processing \u2705 EEG processing \u274c Maxwell filter \u2705 Frequency filter \u2705 SSP \u274c ICA \u2705 Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/ds003392.html#generated-output","text":"Summary reports sub-01_task-localizer_report.html sub-average_task-localizer_report.html Data cleaning sub-01_task-localizer_proc-clean_report.html sub-01_task-localizer_proc-ica_report.html","title":"Generated output"},{"location":"examples/ds003392.html#dataset-source","text":"This dataset was acquired from https://openneuro.org/datasets/ds003392 How to download this dataset Run in your terminal: openneuro-py download \\ --dataset = ds003392 \\ --include = sub-01 \\ --include = sub-emptyroom/ses-19111211","title":"Dataset source"},{"location":"examples/ds003392.html#configuration","text":"study_name = 'localizer' bids_root = '~/mne_data/ds003392' subjects_list = [ '01' ] task = 'localizer' find_flat_channels_meg = True find_noisy_channels_meg = True use_maxwell_filter = True allow_maxshield = True ch_types = [ 'meg' ] l_freq = 1. h_freq = 40. resample_sfreq = 250 # Artifact correction. use_ssp = False use_ica = True ica_max_iterations = 500 ica_l_freq = 1. ica_n_components = 0.99 ica_reject_components = 'auto' # Epochs tmin = - 0.2 tmax = 1.0 baseline = ( None , 0 ) # Conditions / events to consider when epoching conditions = [ 'coherent' , 'incoherent' ] # Decoding decode = True contrasts = [( 'incoherent' , 'coherent' )] # Noise estimation process_er = True noise_cov = 'emptyroom'","title":"Configuration"},{"location":"examples/eeg_matchingpennies.html","text":"Matchingpennies EEG experiment \u00b6 Demonstrated features \u00b6 Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c Generated output \u00b6 Summary reports sub-05_task-matchingpennies_report.html sub-average_task-matchingpennies_report.html Dataset source \u00b6 This dataset was acquired from https://github.com/sappelhoff/eeg_matchingpennies Configuration \u00b6 study_name = 'eeg_matchingpennies' bids_root = '~/mne_data/eeg_matchingpennies' subjects = [ '05' ] task = 'matchingpennies' ch_types = [ 'eeg' ] interactive = False reject = { 'eeg' : 150e-6 } conditions = [ 'left' , 'right' ] contrasts = [( 'right' , 'left' )] decode = True use_ssp = False use_ica = False interpolate_bads_grand_average = False","title":"Matchingpennies EEG experiment"},{"location":"examples/eeg_matchingpennies.html#matchingpennies-eeg-experiment","text":"","title":"Matchingpennies EEG experiment"},{"location":"examples/eeg_matchingpennies.html#demonstrated-features","text":"Feature This example MEG processing \u274c EEG processing \u2705 Maxwell filter \u274c Frequency filter \u2705 SSP \u274c ICA \u274c Evoked contrasts \u2705 Time-by-time decoding \u2705 Time-frequency analysis \u274c BEM surface creation \u274c","title":"Demonstrated features"},{"location":"examples/eeg_matchingpennies.html#generated-output","text":"Summary reports sub-05_task-matchingpennies_report.html sub-average_task-matchingpennies_report.html","title":"Generated output"},{"location":"examples/eeg_matchingpennies.html#dataset-source","text":"This dataset was acquired from https://github.com/sappelhoff/eeg_matchingpennies","title":"Dataset source"},{"location":"examples/eeg_matchingpennies.html#configuration","text":"study_name = 'eeg_matchingpennies' bids_root = '~/mne_data/eeg_matchingpennies' subjects = [ '05' ] task = 'matchingpennies' ch_types = [ 'eeg' ] interactive = False reject = { 'eeg' : 150e-6 } conditions = [ 'left' , 'right' ] contrasts = [( 'right' , 'left' )] decode = True use_ssp = False use_ica = False interpolate_bads_grand_average = False","title":"Configuration"},{"location":"examples/examples.html","text":"Welcome to our examples gallery.","title":"About examples"},{"location":"features/features.html","text":"What the MNE-BIDS-Pipeline can do \u00b6 preprocessing (filtering, artifact rejection) epoching generation of evoked responses contrasting of experimental conditions time-frequency analysis source estimation All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level. Get started","title":"What the pipeline can do"},{"location":"features/features.html#what-the-mne-bids-pipeline-can-do","text":"preprocessing (filtering, artifact rejection) epoching generation of evoked responses contrasting of experimental conditions time-frequency analysis source estimation All intermediate results are saved to disk for later inspection, and an extensive report is generated. Analyses are conducted on individual (per-subject) as well as group level. Get started","title":"What the MNE-BIDS-Pipeline can do"},{"location":"features/steps.html","text":"Processing steps \u00b6 The following table provides a concise summary of each step in the Study Template. You can find the scripts in the scripts directory. Preprocessing \u00b6 Processing step Description preprocessing Run all preprocessing scripts. preprocessing/import_and_maxfilter Import raw data and apply Maxwell filter. preprocessing/frequency_filter Apply low- and high-pass filters. preprocessing/make_epochs Extract epochs. preprocessing/run_ica Run Independant Component Analysis (ICA) for artifact correction. preprocessing/run_ssp Run Signal Subspace Projections (SSP) for artifact correction. These are often also referred to as PCA vectors. preprocessing/apply_ica As an alternative to ICA, you can use SSP projections to correct for eye blink and heart beat artifacts. preprocessing/apply_ssp Apply SSP projections and obtain the cleaned epochs. Sensor-level analysis \u00b6 Processing step Description sensor Run all sensor-level analysis scripts. sensor/make_evoked Extract evoked data for each condition. sensor/sliding_estimator Running a time-by-time decoder with sliding window. sensor/time_frequency Running a time-frequency analysis. sensor/group_average_sensors Make a group average of the time domain data. Source-level analysis \u00b6 Processing step Description source Run all source-level analysis scripts. source/make_forward Compute forward operators. You will need to have computed the coregistration to obtain the -trans.fif files for each subject. source/make_cov Compute noise covariances for each subject. source/make_inverse Compute inverse solution to obtain source estimates. source/group_average Compute source estimates average over subjects. Analysis reports \u00b6 Processing step Description report Run all report-generating scripts (currently only one). report/make_reports.py Compute HTML reports for each subject.","title":"List of processing steps"},{"location":"features/steps.html#processing-steps","text":"The following table provides a concise summary of each step in the Study Template. You can find the scripts in the scripts directory.","title":"Processing steps"},{"location":"features/steps.html#preprocessing","text":"Processing step Description preprocessing Run all preprocessing scripts. preprocessing/import_and_maxfilter Import raw data and apply Maxwell filter. preprocessing/frequency_filter Apply low- and high-pass filters. preprocessing/make_epochs Extract epochs. preprocessing/run_ica Run Independant Component Analysis (ICA) for artifact correction. preprocessing/run_ssp Run Signal Subspace Projections (SSP) for artifact correction. These are often also referred to as PCA vectors. preprocessing/apply_ica As an alternative to ICA, you can use SSP projections to correct for eye blink and heart beat artifacts. preprocessing/apply_ssp Apply SSP projections and obtain the cleaned epochs.","title":"Preprocessing"},{"location":"features/steps.html#sensor-level-analysis","text":"Processing step Description sensor Run all sensor-level analysis scripts. sensor/make_evoked Extract evoked data for each condition. sensor/sliding_estimator Running a time-by-time decoder with sliding window. sensor/time_frequency Running a time-frequency analysis. sensor/group_average_sensors Make a group average of the time domain data.","title":"Sensor-level analysis"},{"location":"features/steps.html#source-level-analysis","text":"Processing step Description source Run all source-level analysis scripts. source/make_forward Compute forward operators. You will need to have computed the coregistration to obtain the -trans.fif files for each subject. source/make_cov Compute noise covariances for each subject. source/make_inverse Compute inverse solution to obtain source estimates. source/group_average Compute source estimates average over subjects.","title":"Source-level analysis"},{"location":"features/steps.html#analysis-reports","text":"Processing step Description report Run all report-generating scripts (currently only one). report/make_reports.py Compute HTML reports for each subject.","title":"Analysis reports"},{"location":"getting_started/basic_usage.html","text":"Prepare your dataset \u00b6 MNE-BIDS-Pipeline only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . We recommend that faulty channels are marked as \"bad\". Why? While we do run automated bad channel detection in the pipeline, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset. How? MNE-BIDS provides a convenient way to visually inspect raw data and interactively mark problematic channels as bad by using the command mne-bids inspect Please see the MNE-BIDS documentation for more information. the data is anonymized before running the pipeline if you require anonymization, as the pipeline itself does not allow for anonymization. Why? This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. How? The write_raw_bids function of MNE-BIDS accepts an anonymize parameter that can be used to anonymize your data by removing subject-identifying information and shifting the measurement date by a given number of days. For example, you could use from mne_bids import write_raw_bids write_raw_bids ( ... , anonymize = dict ( daysback = 1000 )) to shift the recording date 1000 days into the past. By default, information like participant handedness etc. will be removed as well. Please see the documentation of write_raw_bids for more information. Adjust your configuration file \u00b6 The pipeline ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Avoid modifying the scripts You should only need to touch the configuration file. None of the scripts should be edited. Run the pipeline \u00b6 Run the full pipeline To run the full pipeline, execute the following command in your terminal: python run.py --config = /path/to/your/custom_config.py Run only parts of the pipeline Run only the preprocessing steps: python run.py --config = /path/to/your/custom_config.py --steps = preprocessing Run only the sensor-level processing steps: python run.py --config = /path/to/your/custom_config.py --steps = sensor Run only the source-level (inverse solution) processing steps: python run.py --config = /path/to/your/custom_config.py --steps = source Only generate the report: python run.py --config = /path/to/your/custom_config.py --steps = report (Re-)run ICA: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing/ica You can also run multiple steps with one command by separating different steps by a comma. For example, to run preprocessing and sensor-level processing steps using a single command, do: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing,sensor","title":"Basic usage"},{"location":"getting_started/basic_usage.html#prepare-your-dataset","text":"MNE-BIDS-Pipeline only works with BIDS-formatted raw data. To find out more about BIDS and how to convert your data to the BIDS format, please see the documentation of MNE-BIDS . We recommend that faulty channels are marked as \"bad\". Why? While we do run automated bad channel detection in the pipeline, it is considered good practice to flag obviously problematic channels as such in the BIDS dataset. How? MNE-BIDS provides a convenient way to visually inspect raw data and interactively mark problematic channels as bad by using the command mne-bids inspect Please see the MNE-BIDS documentation for more information. the data is anonymized before running the pipeline if you require anonymization, as the pipeline itself does not allow for anonymization. Why? This was a conscious design decision, not a technical limitation per se . If you think this decision should be reconsidered, please get in touch with the developers. How? The write_raw_bids function of MNE-BIDS accepts an anonymize parameter that can be used to anonymize your data by removing subject-identifying information and shifting the measurement date by a given number of days. For example, you could use from mne_bids import write_raw_bids write_raw_bids ( ... , anonymize = dict ( daysback = 1000 )) to shift the recording date 1000 days into the past. By default, information like participant handedness etc. will be removed as well. Please see the documentation of write_raw_bids for more information.","title":"Prepare your dataset"},{"location":"getting_started/basic_usage.html#adjust-your-configuration-file","text":"The pipeline ships with a default configuration file, config.py . You need to create a copy of that configuration file and adjust all parameters that are relevant to your data processing and analysis. Avoid modifying the scripts You should only need to touch the configuration file. None of the scripts should be edited.","title":"Adjust your configuration file"},{"location":"getting_started/basic_usage.html#run-the-pipeline","text":"Run the full pipeline To run the full pipeline, execute the following command in your terminal: python run.py --config = /path/to/your/custom_config.py Run only parts of the pipeline Run only the preprocessing steps: python run.py --config = /path/to/your/custom_config.py --steps = preprocessing Run only the sensor-level processing steps: python run.py --config = /path/to/your/custom_config.py --steps = sensor Run only the source-level (inverse solution) processing steps: python run.py --config = /path/to/your/custom_config.py --steps = source Only generate the report: python run.py --config = /path/to/your/custom_config.py --steps = report (Re-)run ICA: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing/ica You can also run multiple steps with one command by separating different steps by a comma. For example, to run preprocessing and sensor-level processing steps using a single command, do: python run.py --config = /path/to/your/custom_config.py \\ --steps = preprocessing,sensor","title":"Run the pipeline"},{"location":"getting_started/freesurfer.html","text":"To perform inverse modeling, or also called source estimation or source localization, we need to ensure that a couple prerequisities are met. Essentially, starting from a collection of 2-dimensional MRI images of coronal, axial, and saggital slices of a participant's head, we need to construct a 3-dimensional representation of the brain, skull, and scalp. Furthermore, it's highly advantegous to attach labels to different brain areas according to common anatomical atlases, so that we could, for example, restrict subsequent analyses to specific cortical regions, and compare activation in these regions across participants. BIDS raw datasets, however, do not include any of these 3D representations and parcellations. (Note that, however, these derivatives are sometimes distributed along with a datasets inside a derivatives/ folder). Instead, they ship e.g. with T1-weighted images only (and, sometimes, include FLASH images too). Install FreeSurfer \u00b6 Before running the source-analysis parts of the pipeline, you need to create the above-mentioned 3D surfaces and parcellations. This is done using the FreeSurfer tool. FreeSurfer is a free software package that runs on macOS and Linux. To install FreeSurfer 6, follow the official download and installation nstructions . Info The only currently supported FreeSurfer version is 6.0 . Warning FreeSurfer does not natively run on Windows. We are currently working on ways to make it possible to use it on Windows, too. Warning FreeSurfer cannot currently be used on macOS Big Sur (other macOS versions work fine). We are working on a solution. Generate surfaces and brain parcellation \u00b6 MNE-BIDS-Pipeline provides a convenient way to invoke FreeSurfer. After adjusting your configuration file , invoke FreeSurfer via the run.py script in the following way: python run.py freesurfer --config = /path/to/your/custom_config.py This will run the recon-all command to create the required surfaces. Info This process is very computationally expensive, and will usually take several hours to complete. It's a good idea to let this command run over night. Run source-level analyses \u00b6 Now you are ready to run MNE-BIDS-Pipeline, including all parts of inverse modeling. To perform the projection, MNE-Python will first need to detect brain, skull, and skin, so it can then start constructing the actual BEM conductor model. These BEM surfaces can be created based on FLASH MRI (best option) or T1-weighted MRI images (second-best). See the respective configuration options to control BEM surface creation.","title":"Preparations for source-level analyses"},{"location":"getting_started/freesurfer.html#install-freesurfer","text":"Before running the source-analysis parts of the pipeline, you need to create the above-mentioned 3D surfaces and parcellations. This is done using the FreeSurfer tool. FreeSurfer is a free software package that runs on macOS and Linux. To install FreeSurfer 6, follow the official download and installation nstructions . Info The only currently supported FreeSurfer version is 6.0 . Warning FreeSurfer does not natively run on Windows. We are currently working on ways to make it possible to use it on Windows, too. Warning FreeSurfer cannot currently be used on macOS Big Sur (other macOS versions work fine). We are working on a solution.","title":"Install FreeSurfer"},{"location":"getting_started/freesurfer.html#generate-surfaces-and-brain-parcellation","text":"MNE-BIDS-Pipeline provides a convenient way to invoke FreeSurfer. After adjusting your configuration file , invoke FreeSurfer via the run.py script in the following way: python run.py freesurfer --config = /path/to/your/custom_config.py This will run the recon-all command to create the required surfaces. Info This process is very computationally expensive, and will usually take several hours to complete. It's a good idea to let this command run over night.","title":"Generate surfaces and brain parcellation"},{"location":"getting_started/freesurfer.html#run-source-level-analyses","text":"Now you are ready to run MNE-BIDS-Pipeline, including all parts of inverse modeling. To perform the projection, MNE-Python will first need to detect brain, skull, and skin, so it can then start constructing the actual BEM conductor model. These BEM surfaces can be created based on FLASH MRI (best option) or T1-weighted MRI images (second-best). See the respective configuration options to control BEM surface creation.","title":"Run source-level analyses"},{"location":"getting_started/install.html","text":"Install MNE-Python \u00b6 First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions . Install additional dependencies \u00b6 You will also need to install the a number of additional dependencies that are required to run the pipeline. Install for Python 3.8 and newer Run in your terminal: pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Install for older Python versions Run in your terminal: pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extension Detailed list of dependencies mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8 Download MNE-BIDS-Pipeline \u00b6 TODO","title":"Installation"},{"location":"getting_started/install.html#install-mne-python","text":"First, you need to make sure you have MNE-Python installed and working on your system. See the installation instructions .","title":"Install MNE-Python"},{"location":"getting_started/install.html#install-additional-dependencies","text":"You will also need to install the a number of additional dependencies that are required to run the pipeline. Install for Python 3.8 and newer Run in your terminal: pip install mne-bids coloredlogs tqdm pandas scikit-learn json_tricks fire Install for older Python versions Run in your terminal: pip install mne-bids coloredlogs tqdm pandas json_tricks scikit-learn fire typing_extension Detailed list of dependencies mne-bids to operate on BIDS data coloredlogs for nicer logging output tqdm for progress bars pandas for table creation json_tricks for handling of some analysis output scikit-learn for decoding fire for the command line interface typing_extensions if you're using a Python version older than 3.8","title":"Install additional dependencies"},{"location":"getting_started/install.html#download-mne-bids-pipeline","text":"TODO","title":"Download MNE-BIDS-Pipeline"},{"location":"settings/general.html","text":"study_name : str \u00b6 Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study' bids_root : None \u00b6 deriv_root : None \u00b6 subjects_dir : Union [ str , pathlib . Path ] \u00b6 Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software. interactive : bool \u00b6 If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window. crop : Optional [ Tuple [ float , float ]] \u00b6 Crop the raw data to the specified time interval [tmin, tmax] in seconds. If None , do not crop the data. sessions : Union [ List , Literal [ 'all' ]] \u00b6 The sessions to process. task : str \u00b6 The task to process. runs : Union [ Iterable , Literal [ 'all' ]] \u00b6 The runs to process. acq : Optional [ str ] \u00b6 The BIDS acquisition entity. proc : Optional [ str ] \u00b6 The BIDS processing entity. rec : Optional [ str ] \u00b6 The BIDS recording entity. space : Optional [ str ] \u00b6 The BIDS space entity. subjects : Union [ Iterable [ str ], Literal [ 'all' ]] \u00b6 Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02. exclude_subjects : Iterable [ str ] \u00b6 Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically. process_er : bool \u00b6 Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically. ch_types : Iterable [ Literal [ 'meg' , 'mag' , 'grad' , 'eeg' ]] \u00b6 The channel types to consider. Info Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ] data_type : Optional [ Literal [ 'meg' , 'eeg' ]] \u00b6 The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None eog_channels : Optional [ Iterable [ str ]] \u00b6 Specify EOG channels to use, or create virtual EOG channels. Allows the specification of custom channel names that shall be used as (virtual) EOG channels. For example, say you recorded EEG without dedicated EOG electrodes, but with some EEG electrodes placed close to the eyes, e.g. Fp1 and Fp2. These channels can be expected to have captured large quantities of ocular activity, and you might want to use them as \"virtual\" EOG channels, while also including them in the EEG analysis. By default, MNE won't know that these channels are suitable for recovering EOG, and hence won't be able to perform tasks like automated blink removal, unless a \"true\" EOG sensor is present in the data as well. Speficying channel names here allows MNE to find the respective EOG signals based on these channels. You can specify one or multiple channel names. Each will be treated as if it were a dedicated EOG channel, without excluding it from any other analyses. If None , only actual EOG channels will be used for EOG recovery. If there are multiple actual EOG channels in your data, and you only specify a subset of them here, only this subset will be used during processing. Example Treat Fp1 as virtual EOG channel: eog_channels = [ 'Fp1' ] Treat Fp1 and Fp2 as virtual EOG channels: eog_channels = [ 'Fp1' , 'Fp2' ] eeg_bipolar_channels : Optional [ Dict [ str , Tuple [ str , str ]]] \u00b6 Combine two channels into a bipolar channel, whose signal is the difference between the two combined channels, and add it to the data. A typical use case is the combination of two EOG channels \u2013 for example, a left and a right horizontal EOG \u2013 into a single, bipolar EOG channel. You need to pass a dictionary whose keys are the name of the new bipolar channel you wish to create, and whose values are tuples consisting of two strings: the name of the channel acting as anode and the name of the channel acting as cathode, i.e. {'ch_name': ('anode', 'cathode')} . You can request to construct more than one bipolar channel by specifying multiple key/value pairs. See the examples below. Can also be None if you do not want to create bipolar channels. Note The channels used to create the bipolar channels are not automatically dropped from the data. To drop channels, set drop_channels . Example Combine the existing channels HEOG_left and HEOG_right into a new, bipolar channel, HEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' )} Create two bipolar channels, HEOG and VEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'VEOG_upper' )} eeg_reference : Union [ Literal [ 'average' ], str , Iterable [ str ]] \u00b6 The EEG reference to use. If average , will use the average reference, i.e. the average across all channels. If a string, must be the name of a single channel. To use multiple channels as reference, set to a list of channel names. Example Use the average reference: eeg_reference = 'average' Use the P9 channel as reference: eeg_reference = 'P9' Use the average of the P9 and P10 channels as reference: eeg_reference = [ 'P9' , 'P10' ] eeg_template_montage : Optional [ str ] \u00b6 In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64' drop_channels : Iterable [ str ] \u00b6 Names of channels to remove from the data. This can be useful, for example, if you have added a new bipolar channel via eeg_bipolar_channels and now wish to remove the anode, cathode, or both. Example Exclude channels Fp1 and Cz from processing: drop_channels = [ 'Fp1' , 'Cz] analyze_channels : Union [ Literal [ 'all' ], Iterable [ str ]] \u00b6 The names of the channels to analyze during ERP/ERF and time-frequency analysis steps. For certain paradigms, e.g. EEG ERP research, it is common to contrain sensor-space analysis to only a few specific sensors. If 'all' , do not exclude any channels (except for those selected for removal via the drop_channels setting). The constraint will be applied to all sensor-level analyses after the preprocessing stage, but not to the preprocessing stage itself, nor to the source analysis stage. Example Only use channel Pz for ERP, evoked contrasts, time-by-time decoding, and time-frequency analysis: analyze_channels = [ 'Pz' ]","title":"General settings"},{"location":"settings/general.html#config.study_name","text":"Specify the name of your study. It will be used to populate filenames for saving the analysis results. Example study_name = 'my-study'","title":"study_name"},{"location":"settings/general.html#pathlib.bids_root","text":"","title":"bids_root"},{"location":"settings/general.html#pathlib.deriv_root","text":"","title":"deriv_root"},{"location":"settings/general.html#config.subjects_dir","text":"Path to the directory that contains the MRI data files and their derivativesfor all subjects. Specifically, the subjects_dir is the $SUBJECTS_DIR used by the Freesurfer software.","title":"subjects_dir"},{"location":"settings/general.html#config.interactive","text":"If True, the scripts will provide some interactive elements, such as figures. If running the scripts from a notebook or Spyder, run %matplotlib qt in the command line to open the figures in a separate window.","title":"interactive"},{"location":"settings/general.html#config.crop","text":"Crop the raw data to the specified time interval [tmin, tmax] in seconds. If None , do not crop the data.","title":"crop"},{"location":"settings/general.html#config.sessions","text":"The sessions to process.","title":"sessions"},{"location":"settings/general.html#config.task","text":"The task to process.","title":"task"},{"location":"settings/general.html#config.runs","text":"The runs to process.","title":"runs"},{"location":"settings/general.html#config.acq","text":"The BIDS acquisition entity.","title":"acq"},{"location":"settings/general.html#config.proc","text":"The BIDS processing entity.","title":"proc"},{"location":"settings/general.html#config.rec","text":"The BIDS recording entity.","title":"rec"},{"location":"settings/general.html#config.space","text":"The BIDS space entity.","title":"space"},{"location":"settings/general.html#config.subjects","text":"Subjects to analyze. If 'all' , include all subjects. To only include a subset of subjects, pass a list of their identifiers. Even if you plan on analyzing only a single subject, pass their identifier as a list. Please note that if you intend to EXCLUDE only a few subjects, you should consider setting subjects = 'all' and adding the identifiers of the excluded subjects to exclude_subjects (see next section). Example subjects = 'all' # Include all subjects. subjects = [ '05' ] # Only include subject 05. subjects = [ '01' , '02' ] # Only include subjects 01 and 02.","title":"subjects"},{"location":"settings/general.html#config.exclude_subjects","text":"Specify subjects to exclude from analysis. The MEG empty-room mock-subject is automatically excluded from regular analysis. Good Practice / Advice Keep track of the criteria leading you to exclude a participant (e.g. too many movements, missing blocks, aborted experiment, did not understand the instructions, etc, ...) The emptyroom subject will be excluded automatically.","title":"exclude_subjects"},{"location":"settings/general.html#config.process_er","text":"Whether to apply the same pre-processing steps to the empty-room data as to the experimental data (up until including frequency filtering). This is required if you wish to use the empty-room recording to estimate noise covariance (via noise_cov='emptyroom' ). The empty-room recording corresponding to the processed experimental data will be retrieved automatically.","title":"process_er"},{"location":"settings/general.html#config.ch_types","text":"The channel types to consider. Info Currently, MEG and EEG data cannot be processed together. Example # Use EEG channels: ch_types = [ 'eeg' ] # Use magnetometer and gradiometer MEG channels: ch_types = [ 'mag' , 'grad' ] # Currently does not work and will raise an error message: ch_types = [ 'meg' , 'eeg' ]","title":"ch_types"},{"location":"settings/general.html#config.data_type","text":"The BIDS data type. For MEG recordings, this will usually be 'meg'; and for EEG, 'eeg'. However, if your dataset contains simultaneous recordings of MEG and EEG, stored in a single file, you will typically need to set this to 'meg'. If None , we will assume that the data type matches the channel type. Example The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the EEG data, which is stored inside the MEG files: ch_types = [ 'eeg' ] data_type = 'eeg' The dataset contains simultaneous recordings of MEG and EEG, and we only wish to process the gradiometer data: ch_types = [ 'grad' ] data_type = 'meg' # or data_type = None The dataset contains only EEG data: ch_types = [ 'eeg' ] data_type = 'eeg' # or data_type = None","title":"data_type"},{"location":"settings/general.html#config.eog_channels","text":"Specify EOG channels to use, or create virtual EOG channels. Allows the specification of custom channel names that shall be used as (virtual) EOG channels. For example, say you recorded EEG without dedicated EOG electrodes, but with some EEG electrodes placed close to the eyes, e.g. Fp1 and Fp2. These channels can be expected to have captured large quantities of ocular activity, and you might want to use them as \"virtual\" EOG channels, while also including them in the EEG analysis. By default, MNE won't know that these channels are suitable for recovering EOG, and hence won't be able to perform tasks like automated blink removal, unless a \"true\" EOG sensor is present in the data as well. Speficying channel names here allows MNE to find the respective EOG signals based on these channels. You can specify one or multiple channel names. Each will be treated as if it were a dedicated EOG channel, without excluding it from any other analyses. If None , only actual EOG channels will be used for EOG recovery. If there are multiple actual EOG channels in your data, and you only specify a subset of them here, only this subset will be used during processing. Example Treat Fp1 as virtual EOG channel: eog_channels = [ 'Fp1' ] Treat Fp1 and Fp2 as virtual EOG channels: eog_channels = [ 'Fp1' , 'Fp2' ]","title":"eog_channels"},{"location":"settings/general.html#config.eeg_bipolar_channels","text":"Combine two channels into a bipolar channel, whose signal is the difference between the two combined channels, and add it to the data. A typical use case is the combination of two EOG channels \u2013 for example, a left and a right horizontal EOG \u2013 into a single, bipolar EOG channel. You need to pass a dictionary whose keys are the name of the new bipolar channel you wish to create, and whose values are tuples consisting of two strings: the name of the channel acting as anode and the name of the channel acting as cathode, i.e. {'ch_name': ('anode', 'cathode')} . You can request to construct more than one bipolar channel by specifying multiple key/value pairs. See the examples below. Can also be None if you do not want to create bipolar channels. Note The channels used to create the bipolar channels are not automatically dropped from the data. To drop channels, set drop_channels . Example Combine the existing channels HEOG_left and HEOG_right into a new, bipolar channel, HEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' )} Create two bipolar channels, HEOG and VEOG : eeg_add_bipolar_channels = { 'HEOG' : ( 'HEOG_left' , 'HEOG_right' ), 'VEOG' : ( 'VEOG_lower' , 'VEOG_upper' )}","title":"eeg_bipolar_channels"},{"location":"settings/general.html#config.eeg_reference","text":"The EEG reference to use. If average , will use the average reference, i.e. the average across all channels. If a string, must be the name of a single channel. To use multiple channels as reference, set to a list of channel names. Example Use the average reference: eeg_reference = 'average' Use the P9 channel as reference: eeg_reference = 'P9' Use the average of the P9 and P10 channels as reference: eeg_reference = [ 'P9' , 'P10' ]","title":"eeg_reference"},{"location":"settings/general.html#config.eeg_template_montage","text":"In situations where you wish to process EEG data and no individual digitization points (measured channel locations) are available, you can apply a \"template\" montage. This means we will assume the EEG cap was placed either according to an international system like 10/20, or as suggested by the cap manufacturers in their respective manual. Please be aware that the actual cap placement most likely deviated somewhat from the template, and, therefore, source reconstruction may be impaired. If None , do not apply a template montage. If a string, must be the name of a built-in template montage in MNE-Python. You can find an overview of supported template montages at https://mne.tools/stable/generated/mne.channels.make_standard_montage.html Example Do not apply template montage: eeg_template_montage = None Apply 64-channel Biosemi 10/20 template montage: eeg_template_montage = 'biosemi64'","title":"eeg_template_montage"},{"location":"settings/general.html#config.drop_channels","text":"Names of channels to remove from the data. This can be useful, for example, if you have added a new bipolar channel via eeg_bipolar_channels and now wish to remove the anode, cathode, or both. Example Exclude channels Fp1 and Cz from processing: drop_channels = [ 'Fp1' , 'Cz]","title":"drop_channels"},{"location":"settings/general.html#config.analyze_channels","text":"The names of the channels to analyze during ERP/ERF and time-frequency analysis steps. For certain paradigms, e.g. EEG ERP research, it is common to contrain sensor-space analysis to only a few specific sensors. If 'all' , do not exclude any channels (except for those selected for removal via the drop_channels setting). The constraint will be applied to all sensor-level analyses after the preprocessing stage, but not to the preprocessing stage itself, nor to the source analysis stage. Example Only use channel Pz for ERP, evoked contrasts, time-by-time decoding, and time-frequency analysis: analyze_channels = [ 'Pz' ]","title":"analyze_channels"},{"location":"settings/preprocessing/artifacts.html","text":"Good Practice / Advice Have a look at your raw data and train yourself to detect a blink, a heart beat and an eye movement. You can do a quick average of blink data and check what the amplitude looks like. reject : Optional [ dict ] \u00b6 The rejection limits to mark epochs as bads. This allows to remove strong transient artifacts. If you want to reject and retrieve blinks or ECG artifacts later, e.g. with ICA, don't specify a value for the EOG and ECG channels, respectively (see examples below). Pass None to avoid automated epoch rejection based on amplitude. Note These numbers tend to vary between subjects.. You might want to consider using the autoreject method by Jas et al. 2018. See https://autoreject.github.io Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eeg' : 200e-6 } reject = None reject_tmin : Optional [ float ] \u00b6 Start of the time window used to reject epochs. If None , the window will start with the first time point. Example reject_tmin = - 0.1 # 100 ms before event onset. reject_tmax : Optional [ float ] \u00b6 End of the time window used to reject epochs. If None , the window will end with the last time point. Example reject_tmax = 0.3 # 300 ms after event onset.","title":"Amplitude-based artifact removal"},{"location":"settings/preprocessing/artifacts.html#config.reject","text":"The rejection limits to mark epochs as bads. This allows to remove strong transient artifacts. If you want to reject and retrieve blinks or ECG artifacts later, e.g. with ICA, don't specify a value for the EOG and ECG channels, respectively (see examples below). Pass None to avoid automated epoch rejection based on amplitude. Note These numbers tend to vary between subjects.. You might want to consider using the autoreject method by Jas et al. 2018. See https://autoreject.github.io Example reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eog' : 150e-6 } reject = { 'grad' : 4000e-13 , 'mag' : 4e-12 , 'eeg' : 200e-6 } reject = None","title":"reject"},{"location":"settings/preprocessing/artifacts.html#config.reject_tmin","text":"Start of the time window used to reject epochs. If None , the window will start with the first time point. Example reject_tmin = - 0.1 # 100 ms before event onset.","title":"reject_tmin"},{"location":"settings/preprocessing/artifacts.html#config.reject_tmax","text":"End of the time window used to reject epochs. If None , the window will end with the last time point. Example reject_tmax = 0.3 # 300 ms after event onset.","title":"reject_tmax"},{"location":"settings/preprocessing/autobads.html","text":"Warning This functionality will soon be removed from the pipeline, and will be integrated into MNE-BIDS. \"Bad\", i.e. flat and overly noisy channels, can be automatically detected using a procedure inspired by the commercial MaxFilter by Elekta. First, a copy of the data is low-pass filtered at 40 Hz. Then, channels with unusually low variability are flagged as \"flat\", while channels with excessively high variability are flagged as \"noisy\". Flat and noisy channels are marked as \"bad\" and excluded from subsequent analysis. See :func: mne.preprocssessing.find_bad_channels_maxwell for more information on this procedure. The list of bad channels detected through this procedure will be merged with the list of bad channels already present in the dataset, if any. find_flat_channels_meg : bool \u00b6 Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad. find_noisy_channels_meg : bool \u00b6 Auto-detect \"noisy\" channels and mark them as bad.","title":"Bad channel detection"},{"location":"settings/preprocessing/autobads.html#config.find_flat_channels_meg","text":"Auto-detect \"flat\" channels (i.e. those with unusually low variability) and mark them as bad.","title":"find_flat_channels_meg"},{"location":"settings/preprocessing/autobads.html#config.find_noisy_channels_meg","text":"Auto-detect \"noisy\" channels and mark them as bad.","title":"find_noisy_channels_meg"},{"location":"settings/preprocessing/epochs.html","text":"rename_events : dict \u00b6 A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' } event_repeated : Literal [ 'error' , 'drop' , 'merge' ] \u00b6 How to handle repeated events. We call events \"repeated\" if more than one event occurred at the exact same time point. Currently, MNE-Python cannot handle this situation gracefully when trying to create epochs, and will throw an error. To only keep the event of that time point (\"first\" here referring to the order that events appear in *_events.tsv ), pass 'drop' . You can also request to create a new type of event by merging repeated events by setting this to 'merge' . Warning The 'merge' option is entirely untested in the MNE BIDS Pipeline as of April 1st, 2021. conditions : Union [ Iterable [ str ], Dict [ str , str ]] \u00b6 The time-locked events based on which to create evoked responses. This can either be name of the experimental condition as specified in the BIDS *_events.tsv file; or the name of condition groups , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Passing a dictionary allows to assign a name to map a complex condition name (value) to a more legible one (value). Example Specifying conditions as lists of strings: conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ] Pass a dictionary to define a mapping: ```python conditions = {'simple_name': 'complex/condition/with_subconditions'} conditions = {'correct': 'response/correct', 'incorrect': 'response/incorrect'} epochs_tmin : float \u00b6 The beginning of an epoch, relative to the respective event, in seconds. Example epochs_tmin = - 0.2 # 200 ms before event onset epochs_tmax : float \u00b6 The end of an epoch, relative to the respective event, in seconds. Example epochs_tmax = 0.5 # 500 ms after event onset baseline : Optional [ Tuple [ Union [ float , NoneType ], Union [ float , NoneType ]]] \u00b6 Specifies which time interval to use for baseline correction of epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # beginning of epoch until time point zero epochs_metadata_tmin : Optional [ float ] \u00b6 The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If None , use the first time point of the epoch. epochs_metadata_tmax : Optional [ float ] \u00b6 Same as epochs_metadata_tmin , but specifying the end of the time window for metadata generation.","title":"Epoching"},{"location":"settings/preprocessing/epochs.html#config.rename_events","text":"A dictionary specifying which events in the BIDS dataset to rename upon loading, and before processing begins. Pass an empty dictionary to not perform any renaming. Example Rename audio_left in the BIDS dataset to audio/left in the pipeline: rename_events = { 'audio_left' : 'audio/left' }","title":"rename_events"},{"location":"settings/preprocessing/epochs.html#config.event_repeated","text":"How to handle repeated events. We call events \"repeated\" if more than one event occurred at the exact same time point. Currently, MNE-Python cannot handle this situation gracefully when trying to create epochs, and will throw an error. To only keep the event of that time point (\"first\" here referring to the order that events appear in *_events.tsv ), pass 'drop' . You can also request to create a new type of event by merging repeated events by setting this to 'merge' . Warning The 'merge' option is entirely untested in the MNE BIDS Pipeline as of April 1st, 2021.","title":"event_repeated"},{"location":"settings/preprocessing/epochs.html#config.conditions","text":"The time-locked events based on which to create evoked responses. This can either be name of the experimental condition as specified in the BIDS *_events.tsv file; or the name of condition groups , if the condition names contain the (MNE-specific) group separator, / . See the Subselecting epochs tutorial for more information. Passing a dictionary allows to assign a name to map a complex condition name (value) to a more legible one (value). Example Specifying conditions as lists of strings: conditions = [ 'auditory/left' , 'visual/left' ] conditions = [ 'auditory/left' , 'auditory/right' ] conditions = [ 'auditory' ] # All \"auditory\" conditions (left AND right) conditions = [ 'auditory' , 'visual' ] conditions = [ 'left' , 'right' ] Pass a dictionary to define a mapping: ```python conditions = {'simple_name': 'complex/condition/with_subconditions'} conditions = {'correct': 'response/correct', 'incorrect': 'response/incorrect'}","title":"conditions"},{"location":"settings/preprocessing/epochs.html#config.epochs_tmin","text":"The beginning of an epoch, relative to the respective event, in seconds. Example epochs_tmin = - 0.2 # 200 ms before event onset","title":"epochs_tmin"},{"location":"settings/preprocessing/epochs.html#config.epochs_tmax","text":"The end of an epoch, relative to the respective event, in seconds. Example epochs_tmax = 0.5 # 500 ms after event onset","title":"epochs_tmax"},{"location":"settings/preprocessing/epochs.html#config.baseline","text":"Specifies which time interval to use for baseline correction of epochs; if None , no baseline correction is applied. Example baseline = ( None , 0 ) # beginning of epoch until time point zero","title":"baseline"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_tmin","text":"The beginning of the time window for metadata generation, in seconds, relative to the time-locked event of the respective epoch. This may be less than or larger than the epoch's first time point. If None , use the first time point of the epoch.","title":"epochs_metadata_tmin"},{"location":"settings/preprocessing/epochs.html#config.epochs_metadata_tmax","text":"Same as epochs_metadata_tmin , but specifying the end of the time window for metadata generation.","title":"epochs_metadata_tmax"},{"location":"settings/preprocessing/filter.html","text":"It is typically better to set your filtering properties on the raw data so as to avoid what we call border (or edge) effects. If you use this pipeline for evoked responses, you could consider a low-pass filter cut-off of h_freq = 40 Hz and possibly a high-pass filter cut-off of l_freq = 1 Hz so you would preserve only the power in the 1Hz to 40 Hz band. Note that highpass filtering is not necessarily recommended as it can distort waveforms of evoked components, or simply wash out any low frequency that can may contain brain signal. It can also act as a replacement for baseline correction in Epochs. See below. If you use this pipeline for time-frequency analysis, a default filtering coult be a high-pass filter cut-off of l_freq = 1 Hz a low-pass filter cut-off of h_freq = 120 Hz so you would preserve only the power in the 1Hz to 120 Hz band. If you need more fancy analysis, you are already likely past this kind of tips! \ud83d\ude07 l_freq : Optional [ float ] \u00b6 The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied. h_freq : Optional [ float ] \u00b6 The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied.","title":"Filtering"},{"location":"settings/preprocessing/filter.html#config.l_freq","text":"The low-frequency cut-off in the highpass filtering step. Keep it None if no highpass filtering should be applied.","title":"l_freq"},{"location":"settings/preprocessing/filter.html#config.h_freq","text":"The high-frequency cut-off in the lowpass filtering step. Keep it None if no lowpass filtering should be applied.","title":"h_freq"},{"location":"settings/preprocessing/maxfilter.html","text":"use_maxwell_filter : bool \u00b6 Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter. mf_st_duration : Optional [ float ] \u00b6 There are two kinds of maxfiltering: SSS (signal space separation) and tSSS (temporal signal space separation) (see Taulu et al., 2004 ). If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter. mf_head_origin \u00b6 mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto' mf_reference_run : Optional [ str ] \u00b6 Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\" mf_cal_fname : Optional [ str ] \u00b6 Warning This parameter should only be used for BIDS datasets that don't store the fine-calibration file according to BIDS . Path to the Maxwell Filter calibration file. If None the recommended location is used. Example mf_cal_fname = '/path/to/your/file/calibration_cal.dat' mf_ctc_fname : Optional [ str ] \u00b6 Path to the Maxwell Filter cross-talk file. If None the recommended location is used. Warning This parameter should only be used for BIDS datasets that don't store the cross-talk file according to BIDS . Example mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'","title":"Maxwell filter"},{"location":"settings/preprocessing/maxfilter.html#config.use_maxwell_filter","text":"Whether or not to use Maxwell filtering to preprocess the data. Warning If the data were recorded with internal active compensation (MaxShield), they need to be run through Maxwell filter to avoid distortions. Bad channels need to be set through BIDS channels.tsv and / or via the find_flat_channels_meg and find_noisy_channels_meg options above before applying Maxwell filter.","title":"use_maxwell_filter"},{"location":"settings/preprocessing/maxfilter.html#config.mf_st_duration","text":"There are two kinds of maxfiltering: SSS (signal space separation) and tSSS (temporal signal space separation) (see Taulu et al., 2004 ). If not None, apply spatiotemporal SSS (tSSS) with specified buffer duration (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2. Spatiotemporal SSS acts as implicitly as a high-pass filter where the cut-off frequency is 1/st_dur Hz. For this (and other) reasons, longer buffers are generally better as long as your system can handle the higher memory usage. To ensure that each window is processed identically, choose a buffer length that divides evenly into your data. Any data at the trailing edge that doesn't fit evenly into a whole buffer window will be lumped into the previous buffer. Good Practice / Advice If you are interested in low frequency activity (<0.1Hz), avoid using tSSS and set mf_st_duration to None . If you are interested in low frequency above 0.1 Hz, you can use the default mf_st_duration to 10 s, meaning it acts like a 0.1 Hz high-pass filter. Example mf_st_duration = None mf_st_duration = 10. # to apply tSSS with 0.1Hz highpass filter.","title":"mf_st_duration"},{"location":"settings/preprocessing/maxfilter.html#config.mf_head_origin","text":"mf_head_origin : array-like, shape (3,) | 'auto' Origin of internal and external multipolar moment space in meters. If 'auto', it will be estimated from headshape points. If automatic fitting fails (e.g., due to having too few digitization points), consider separately calling the fitting function with different options or specifying the origin manually. Example mf_head_origin = 'auto'","title":"mf_head_origin"},{"location":"settings/preprocessing/maxfilter.html#config.mf_reference_run","text":"Despite all possible care to avoid movements in the MEG, the participant will likely slowly drift down from the Dewar or slightly shift the head around in the course of the recording session. Hence, to take this into account, we are realigning all data to a single position. For this, you need to define a reference run (typically the one in the middle of the recording session). Which run to take as the reference for adjusting the head position of all runs. If None , pick the first run. Example mf_reference_run = '01' # Use run \"01\"","title":"mf_reference_run"},{"location":"settings/preprocessing/maxfilter.html#config.mf_cal_fname","text":"Warning This parameter should only be used for BIDS datasets that don't store the fine-calibration file according to BIDS . Path to the Maxwell Filter calibration file. If None the recommended location is used. Example mf_cal_fname = '/path/to/your/file/calibration_cal.dat'","title":"mf_cal_fname"},{"location":"settings/preprocessing/maxfilter.html#config.mf_ctc_fname","text":"Path to the Maxwell Filter cross-talk file. If None the recommended location is used. Warning This parameter should only be used for BIDS datasets that don't store the cross-talk file according to BIDS . Example mf_ctc_fname = '/path/to/your/file/crosstalk_ct.fif'","title":"mf_ctc_fname"},{"location":"settings/preprocessing/resample.html","text":"If you have acquired data with a very high sampling frequency (e.g. 2 kHz) you will likely want to downsample to lighten up the size of the files you are working with (pragmatics) If you are interested in typical analysis (up to 120 Hz) you can typically resample your data down to 500 Hz without preventing reliable time-frequency exploration of your data. resample_sfreq : Optional [ float ] \u00b6 Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz decim : int \u00b6 Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4","title":"Resampling"},{"location":"settings/preprocessing/resample.html#config.resample_sfreq","text":"Specifies at which sampling frequency the data should be resampled. If None then no resampling will be done. Example resample_sfreq = None # no resampling resample_sfreq = 500 # resample to 500Hz","title":"resample_sfreq"},{"location":"settings/preprocessing/resample.html#config.decim","text":"Says how much to decimate data at the epochs level. It is typically an alternative to the resample_sfreq parameter that can be used for resampling raw data. 1 means no decimation. Good Practice / Advice Decimation requires to lowpass filtered the data to avoid aliasing. Note that using decimation is much faster than resampling. Example decim = 1 # no decimation decim = 4 # decimate by 4 ie devide sampling frequency by 4","title":"decim"},{"location":"settings/preprocessing/ssp_ica.html","text":"use_ssp : bool \u00b6 Whether signal-space projection should be used or not. use_ica : bool \u00b6 Whether independent component analysis should be used or not. ica_algorithm : Literal [ 'picard' , 'fastica' , 'extended_infomax' ] \u00b6 The ICA algorithm to use. ica_l_freq : Optional [ float ] \u00b6 The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA. ica_max_iterations : int \u00b6 Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence. ica_n_components : Union [ float , int ] \u00b6 MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA. ica_decim : Optional [ int ] \u00b6 The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation. ica_ctps_ecg_threshold : float \u00b6 The threshold parameter passed to find_bads_ecg method. ica_eog_threshold : float \u00b6 The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","title":"SSP & ICA"},{"location":"settings/preprocessing/ssp_ica.html#config.use_ssp","text":"Whether signal-space projection should be used or not.","title":"use_ssp"},{"location":"settings/preprocessing/ssp_ica.html#config.use_ica","text":"Whether independent component analysis should be used or not.","title":"use_ica"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_algorithm","text":"The ICA algorithm to use.","title":"ica_algorithm"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_l_freq","text":"The cutoff frequency of the high-pass filter to apply before running ICA. Using a relatively high cutoff like 1 Hz will remove slow drifts from the data, yielding improved ICA results. Set to None to not apply an additional high-pass filter. Note The filter will be applied to raw data which was already filtered according to the l_freq and h_freq settings. After filtering, the data will be epoched, and the epochs will be submitted to ICA.","title":"ica_l_freq"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_max_iterations","text":"Maximum number of iterations to decompose the data into independent components. A low number means to finish earlier, but the consequence is that the algorithm may not have finished converging. To ensure convergence, pick a high number here (e.g. 3000); yet the algorithm will terminate as soon as it determines that is has successfully converged, and not necessarily exhaust the maximum number of iterations. Note that the default of 200 seems to be sufficient for Picard in many datasets, because it converges quicker than the other algorithms; but e.g. for FastICA, this limit may be too low to achieve convergence.","title":"ica_max_iterations"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_n_components","text":"MNE conducts ICA as a sort of a two-step procedure: First, a PCA is run on the data (trying to exclude zero-valued components in rank-deficient data); and in the second step, the principal componenets are passed to the actual ICA. You can select how many of the total principal components to pass to ICA \u2013 it can be all or just a subset. This determines how many independent components to fit, and can be controlled via this setting. If int, specifies the number of principal components that are passed to the ICA algorithm, which will be the number of independent components to fit. It must not be greater than the rank of your data (which is typically the number of channels, but may be less in some cases). If float between 0 and 1, all principal components with cumulative explained variance less than the value specified here will be passed to ICA. If None , all principal components will be used. This setting may drastically alter the time required to compute ICA.","title":"ica_n_components"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_decim","text":"The decimation parameter to compute ICA. If 5 it means that 1 every 5 sample is used by ICA solver. The higher the faster it is to run but the less data you have to compute a good ICA. Set to 1 or None to not perform any decimation.","title":"ica_decim"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_ctps_ecg_threshold","text":"The threshold parameter passed to find_bads_ecg method.","title":"ica_ctps_ecg_threshold"},{"location":"settings/preprocessing/ssp_ica.html#config.ica_eog_threshold","text":"The threshold to use during automated EOG classification. Lower values mean that more ICs will be identified as EOG-related. If too low, the false-alarm rate increases dramatically.","title":"ica_eog_threshold"},{"location":"settings/preprocessing/stim_artifact.html","text":"When using electric stimulation systems, e.g. for median nerve or index stimulation, it is frequent to have a stimulation artifact. This option allows to fix it by linear interpolation early in the pipeline on the raw data. fix_stim_artifact : bool \u00b6 Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False stim_artifact_tmin : float \u00b6 Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset stim_artifact_tmax : float \u00b6 End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation","title":"Stimulation artifact"},{"location":"settings/preprocessing/stim_artifact.html#config.fix_stim_artifact","text":"Apply interpolation to fix stimulation artifact. Example fix_stim_artifact = False","title":"fix_stim_artifact"},{"location":"settings/preprocessing/stim_artifact.html#config.stim_artifact_tmin","text":"Start time of the interpolation window in seconds. Example stim_artifact_tmin = 0. # on stim onset","title":"stim_artifact_tmin"},{"location":"settings/preprocessing/stim_artifact.html#config.stim_artifact_tmax","text":"End time of the interpolation window in seconds. Example stim_artifact_tmax = 0.01 # up to 10ms post-stimulation","title":"stim_artifact_tmax"},{"location":"settings/sensor/statistics.html","text":"contrasts : Iterable [ Tuple [ str , str ]] \u00b6 The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )] decode : bool \u00b6 Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs. decoding_metric : str \u00b6 The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance. decoding_n_splits : int \u00b6 The number of folds (a.k.a. splits) to use in the cross-validation. n_boot : int \u00b6 The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score.","title":"Statistics"},{"location":"settings/sensor/statistics.html#config.contrasts","text":"The conditions to contrast via a subtraction of ERPs / ERFs. Each tuple in the list corresponds to one contrast. The condition names must be specified in conditions above. Pass an empty list to avoid calculation of contrasts. Example Contrast the \"left\" and the \"right\" conditions by calculating left - right at every time point of the evoked responses: conditions = [ 'left' , 'right' ] contrasts = [( 'left' , 'right' )] # Note we pass a tuple inside the list! Contrast the \"left\" and the \"right\" conditions within the \"auditory\" and the \"visual\" modality, and \"auditory\" vs \"visual\" regardless of side: conditions = [ 'auditory/left' , 'auditory/right' , 'visual/left' , 'visual/right' ] contrasts = [( 'auditory/left' , 'auditory/right' ), ( 'visual/left' , 'visual/right' ), ( 'auditory' , 'visual' )]","title":"contrasts"},{"location":"settings/sensor/statistics.html#config.decode","text":"Whether to perform decoding (MVPA) on the contrasts specified above as \"contrasts\". MVPA will be performed on the level of individual epochs.","title":"decode"},{"location":"settings/sensor/statistics.html#config.decoding_metric","text":"The metric to use for cross-validation. It can be 'roc_auc' or 'accuracy' or any other metric supported by scikit-learn . With AUC, chance level is the same regardless of class balance.","title":"decoding_metric"},{"location":"settings/sensor/statistics.html#config.decoding_n_splits","text":"The number of folds (a.k.a. splits) to use in the cross-validation.","title":"decoding_n_splits"},{"location":"settings/sensor/statistics.html#config.n_boot","text":"The number of bootstrap resamples when estimating the standard error and confidence interval of the mean decoding score.","title":"n_boot"},{"location":"settings/sensor/time_freq.html","text":"time_frequency_conditions : Iterable [ str ] \u00b6 The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ]","title":"Time-frequency analysis"},{"location":"settings/sensor/time_freq.html#config.time_frequency_conditions","text":"The conditions to compute time-frequency decomposition on. Example time_frequency_conditions = [ 'left' , 'right' ]","title":"time_frequency_conditions"},{"location":"settings/source/bem.html","text":"bem_mri_images : Literal [ 'FLASH' , 'T1' , 'auto' ] \u00b6 Which types of MRI images to use when creating the BEM model. If 'FLASH' , use FLASH MRI images, and raise an exception if they cannot be found. Advice It is recommended to use the FLASH images if available, as the quality of the extracted BEM surfaces will be higher. If 'T1' , create the BEM surfaces from the T1-weighted images using the watershed algorithm. If 'auto' , use FLASH images if available, and use the watershed algorithm with the T1-weighted images otherwise. recreate_bem : bool \u00b6 Whether to re-create the BEM surfaces, even if existing surfaces have been found. If False , the BEM surfaces are only created if they do not exist already. True forces their recreation, overwriting existing BEM surfaces.","title":"BEM surface"},{"location":"settings/source/bem.html#config.bem_mri_images","text":"Which types of MRI images to use when creating the BEM model. If 'FLASH' , use FLASH MRI images, and raise an exception if they cannot be found. Advice It is recommended to use the FLASH images if available, as the quality of the extracted BEM surfaces will be higher. If 'T1' , create the BEM surfaces from the T1-weighted images using the watershed algorithm. If 'auto' , use FLASH images if available, and use the watershed algorithm with the T1-weighted images otherwise.","title":"bem_mri_images"},{"location":"settings/source/bem.html#config.recreate_bem","text":"Whether to re-create the BEM surfaces, even if existing surfaces have been found. If False , the BEM surfaces are only created if they do not exist already. True forces their recreation, overwriting existing BEM surfaces.","title":"recreate_bem"},{"location":"settings/source/forward.html","text":"spacing : Union [ Literal [ 'oct5' , 'oct6' , 'ico4' , 'ico5' , 'all' ], int ] \u00b6 The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use appoximate distance-based spacing (in mm). See (the respective MNE-Python documentation) [https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space] for more info. mindist : float \u00b6 Exclude points closer than this distance (mm) to the bounding surface.","title":"Source space & forward solution"},{"location":"settings/source/forward.html#config.spacing","text":"The spacing to use. Can be 'ico#' for a recursively subdivided icosahedron, 'oct#' for a recursively subdivided octahedron, 'all' for all points, or an integer to use appoximate distance-based spacing (in mm). See (the respective MNE-Python documentation) [https://mne.tools/dev/overview/cookbook.html#setting-up-the-source-space] for more info.","title":"spacing"},{"location":"settings/source/forward.html#config.mindist","text":"Exclude points closer than this distance (mm) to the bounding surface.","title":"mindist"},{"location":"settings/source/general.html","text":"run_source_estimation : bool \u00b6 Whether to run source estimation processing steps if not explicitly requested.","title":"General settings"},{"location":"settings/source/general.html#config.run_source_estimation","text":"Whether to run source estimation processing steps if not explicitly requested.","title":"run_source_estimation"},{"location":"settings/source/inverse.html","text":"inverse_method : Literal [ 'MNE' , 'dSPM' , 'sLORETA' , 'eLORETA' ] \u00b6 Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution. noise_cov : Optional [ Tuple [ Union [ float , NoneType ], Union [ float ]], Literal [ 'emptyroom' ]] \u00b6 Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom'","title":"Inverse solution"},{"location":"settings/source/inverse.html#config.inverse_method","text":"Use minimum norm, dSPM (default), sLORETA, or eLORETA to calculate the inverse solution.","title":"inverse_method"},{"location":"settings/source/inverse.html#config.noise_cov","text":"Specify how to estimate the noise covariance matrix, which is used in inverse modeling. If a tuple, it takes the form (tmin, tmax) with the time specified in seconds. If the first value of the tuple is None , the considered period starts at the beginning of the epoch. If the second value of the tuple is None , the considered period ends at the end of the epoch. The default, (None, 0) , includes the entire period before the event, which is typically the pre-stimulus period. If emptyroom , the noise covariance matrix will be estimated from an empty-room MEG recording. The empty-room recording will be automatically selected based on recording date and time. Please note that when processing data that contains EEG channels, the noise covariance can ONLY be estimated from the pre-stimulus period. Example Use the period from start of the epoch until 100 ms before the experimental event: noise_cov = ( None , - 0.1 ) Use the time period from the experimental event until the end of the epoch: noise_cov = ( 0 , None ) Use an empty-room recording: noise_cov = 'emptyroom'","title":"noise_cov"}]}